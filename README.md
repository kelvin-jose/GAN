## mini Generative Adversarial Networks (mGANs)

Deep neural networks are used mainly for supervised learning: classification or regression. Generative Adverserial Networks or GANs, however, use neural networks for a very different purpose: Generative modeling

> Generative modeling is an unsupervised learning task in machine learning that involves automatically discovering and learning the regularities or patterns in input data in such a way that the model can be used to generate or output new examples that plausibly could have been drawn from the original dataset. - [Source]

![GAN Architecture](https://pathmind.com/images/wiki/gan_schema.png)
There are two neural networks: a _Generator_ and a _Discriminator_. The generator generates a "fake" sample given a random vector/matrix, and the discriminator attempts to detect whether a given sample is "real" (picked from the training data) or "fake" (generated by the generator). Training happens in tandem: we train the discriminator for a few epochs, then train the generator for a few epochs, and repeat. This way both the generator and the discriminator get better at doing their jobs.

Here is a good explanation of the complex process including video examples: [https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/](https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/). You can safely ignore a lot of the details and still get a very good understanding. [(YouTube video)](https://youtu.be/kSLJriaOumA)

## Are GANs Dangerous?

The images created by the networks we have discussed here are probably not too dangerous in and of themselves. They could be used in videos or elsewhere and not require model releases, for example, and the deception would be relatively harmless. But that is not universally the case.

[An article from Nextgov](https://www.nextgov.com/emerging-tech/2019/04/newest-ai-enabled-weapon-deep-faking-photos-earth/155962/) describes how deceptive satellite images could be created using GANs and how those could be used by an adversary in a military context. There are significant private sector concerns as well. At the core of these issues is whether or not data can be trusted. If we see an image of a person, is she real or generated by AI? If we see a satellite image, is it real or generated by AI? People tend to believe what they see – or think they see – and faked images can be even more convincing than a stage magician.




